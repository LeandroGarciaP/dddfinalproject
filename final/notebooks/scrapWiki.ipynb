{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Modelo de extração da tabela de Clubes de Futebol na Wikipédia"},{"metadata":{},"cell_type":"markdown","source":"**Fonte:** [Participação dos Clubes no Campeonato Brasileiro de Futebol](https://pt.wikipedia.org/wiki/Participa%C3%A7%C3%B5es_dos_clubes_no_Campeonato_Brasileiro_de_Futebol)"},{"metadata":{},"cell_type":"markdown","source":"> Nesse Modelo, extraímos a tabela bruta com os dados dos Clubes do site da Wikipédia utilizando `webscrapping`, bem como obtemos os links para todas as páginas da Wiki que referenciam esses clubes, com o intuito de utilizar esses links para acessar o recurso de todos os clubes na DBPedia e através do modelo estruturado recuperar informações individuais dos clubes como `Nome Completo`, `Apelido` e `Data de Fundação` "},{"metadata":{},"cell_type":"markdown","source":">Ao final da execução, teremos o arquivo `clubes_raw.csv` contendo os dados da tabela bruta, dois arquivos `links_v0.csv` e `links_v1.csv` sendo o primeiro sem nenhum tratamento e o segundo com a adição de um link faltante no site e remoção de comentários que integravam a tabela. Por fim, o arquivo `dbconcepts.csv` é criado com as referências a serem utilizadas para busca dos recursos posteriormente na DBPedia"},{"metadata":{},"cell_type":"markdown","source":"### Rotina Completa em Python"},{"metadata":{"trusted":true},"cell_type":"code","source":"from os import link\nfrom bs4 import BeautifulSoup\nimport requests\nimport pandas as pd\n\nwiki_url = 'https://pt.wikipedia.org/wiki/Participa%C3%A7%C3%B5es_dos_clubes_no_Campeonato_Brasileiro_de_Futebol'\n\nname = 'wikitable sortable'\n\nresponse = requests.get(wiki_url)\n\nsoup = BeautifulSoup(response.text, 'html.parser')\n\n#tabela dos clubes\nteams_table = soup.find('table',{'class':name})\n\n\n\n################################################\n# Obtendo os links para referência no DBPedia: #\n################################################\n\nlinks=[]\n#cria lista com todos os links da tabela\nfor a in teams_table.find_all('a', href=True):\n    if a.text:\n        links.append(a['href'])\n\n#Um dos links da tabela de clubes estava faltando:\nlinks.insert(772, \"/wiki/Ficheiro:Duque_de_Caxias(MA)\")\n\n\n#Arquivo com os Links sem tratamento nenhum\ndict = {'Reference': links}\ndf2 = pd.DataFrame(dict)\ndf2.to_csv('links_v0.csv', index=False)\n\n\n# O arquivo veio com algumas linhas de comentários indesejáveis\nlinks = [x for x in links if x[0] != \"#\"]\ndict = {'Reference': links}\ndf3 = pd.DataFrame(dict)\ndf3.to_csv('links_v1.csv', index=False)\n\nconcepts = []\n#limpa a lista deixando apenas a parte que interessa dos links e apenas dos clubes\nfor i in range(4, len(links), 2):\n    #links[i] = links[i][6: ]\n    concepts.append(links[i][6:])      #retira os 6 primeiros char da lista \"links\"\n\n\n#Exportando a lista dos concepts em um csv\ndict = {'Reference': concepts}\ndf1 = pd.DataFrame(dict)\ndf1.to_csv('dbconcepts.csv', index=False)\n\n\n\n\n############################################\n# Obtendo a tabela dos clubes da Wikipédia #\n############################################\n\ndf = pd.read_html(str(teams_table))         #read_html retorna uma lista\n\ndf = df[0]      #converte em um dataframe\n\ndf.to_csv('clubes_raw.csv')\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":5}